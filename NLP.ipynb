{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a71e99a",
   "metadata": {},
   "source": [
    "–ö–æ–¥ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82a18168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\tokenizer_config.json\n",
      "Adding @@–ü–ï–†–í–´–ô@@ to the vocabulary\n",
      "Adding @@–í–¢–û–†–û–ô@@ to the vocabulary\n",
      "Adding <FIRST_SPEAKER> to the vocabulary\n",
      "Adding <SECOND_SPEAKER> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"tinkoff-ai/ruDialoGPT-medium\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"n_special\": 0,\n",
      "  \"output_past\": true,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50261\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Daniel/.cache\\huggingface\\hub\\models--tinkoff-ai--ruDialoGPT-medium\\snapshots\\e51fe3a6ea7037f3f53938e3a58ee6e40a82fce3\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at tinkoff-ai/ruDialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50257 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@@–ü–ï–†–í–´–ô@@ –ø—Ä–∏–≤–µ—Ç @@–í–¢–û–†–û–ô@@ –ø—Ä–∏–≤–µ—Ç @@–ü–ï–†–í–´–ô@@ –∫–∞–∫ –¥–µ–ª–∞? @@–í–¢–û–†–û–ô@@–Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∞ —É —Ç–µ–±—è? –ö–∞–∫ —Å–∞–º? –ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ –∂–∏–∑–Ω–∏? –Ø –≤–æ—Ç –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å–∏–∂—É –∏ –¥—É–º–∞—é, —á–µ–º –∑–∞–Ω—è—Ç—å—Å—è. –ê —Ç—ã? –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è? =) ^_^@@–í–¢–û–†–û–ô@@',\n",
       " '@@–ü–ï–†–í–´–ô@@ –ø—Ä–∏–≤–µ—Ç @@–í–¢–û–†–û–ô@@ –ø—Ä–∏–≤–µ—Ç @@–ü–ï–†–í–´–ô@@ –∫–∞–∫ –¥–µ–ª–∞? @@–í–¢–û–†–û–ô@@–ø—Ä–∏–≤–µ—Ç  —Ö–æ—Ä–æ—à–æ. –∞ —É —Ç–µ–±—è –∫–∞–∫? —á—Ç–æ –¥–µ–ª–∞–µ—à—å? —á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è? —è —Ç–æ–∂–µ —Ö–æ—á—É –ø–æ–≥—É–ª—è—Ç—å —Å —Ç–æ–±–æ–π üëâüèª\\u200d‚ôÄÔ∏èÔøΩ',\n",
       " '@@–ü–ï–†–í–´–ô@@ –ø—Ä–∏–≤–µ—Ç @@–í–¢–û–†–û–ô@@ –ø—Ä–∏–≤–µ—Ç @@–ü–ï–†–í–´–ô@@ –∫–∞–∫ –¥–µ–ª–∞? @@–í–¢–û–†–û–ô@@–Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∞ —É —Ç–µ–±—è? –ö–∞–∫ —Å–∞–º–∞? –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è? –ß—Ç–æ –¥–µ–ª–∞–µ—à—å? –Ø –≤–æ—Ç —Å–∏–∂—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç. ü§∑\\u200d‚ôÇÔøΩ']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('tinkoff-ai/ruDialoGPT-medium')\n",
    "model = AutoModelWithLMHead.from_pretrained('tinkoff-ai/ruDialoGPT-medium')\n",
    "inputs = tokenizer('@@–ü–ï–†–í–´–ô@@ –ø—Ä–∏–≤–µ—Ç @@–í–¢–û–†–û–ô@@ –ø—Ä–∏–≤–µ—Ç @@–ü–ï–†–í–´–ô@@ –∫–∞–∫ –¥–µ–ª–∞? @@–í–¢–û–†–û–ô@@', return_tensors='pt')\n",
    "generated_token_ids = model.generate(\n",
    "    **inputs,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    num_beams=3,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=1.2,\n",
    "    repetition_penalty=1.2,\n",
    "    length_penalty=1.0,\n",
    "    eos_token_id=50257,\n",
    "    max_new_tokens=40\n",
    ")\n",
    "context_with_response = [tokenizer.decode(sample_token_ids) for sample_token_ids in generated_token_ids]\n",
    "context_with_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ceb4d",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —á–∞—Ç–∞ –≤–æ–∑—å–º—ë–º CCM - —á–∞—Ç Chess Club Moscow, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–±—Å—É–∂–¥–∞—é—Ç —à–∞—Ö–º–∞—Ç—ã –∏ –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞—é—Ç—Å—è –æ–± –∏–≥—Ä–∞—Ö –∏ —Ç—É—Ä–Ω–∏—Ä–∞—Ö –≤ –∫–ª—É–±–µ: https://t.me/pairwccm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c68d0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"ccm.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bd1b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'type', 'date', 'date_unixtime', 'actor', 'actor_id', 'action', 'title', 'text', 'text_entities'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"messages\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1696382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3d0f6",
   "metadata": {},
   "source": [
    "–£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø—Ä–æ—á–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "894b1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = lambda msg: len(msg[\"text\"]) > 0 and type(msg[\"text\"]) == str\n",
    "\n",
    "raw_texts = [msg[\"text\"] for msg in data[\"messages\"] if condition(msg)]\n",
    "users = [msg.get(\"from_id\") for msg in data[\"messages\"] if condition(msg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59dc27",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π –µ—Å–ª–∏ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥, —Ç–æ —Å–∫–ª–µ–∏–≤–∞–µ–º –∏—Ö –≤ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ. –¢–∞–∫ –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –º–µ—Ç–∫–∏ @@–ü–ï–†–í–´–ô@@ –∏ @@–í–¢–û–†–û–ô@@, —Ç–æ –¥–æ–±–∞–≤–∏–º –∏—Ö –≤ –Ω–∞—à—É –≤—ã–±–æ—Ä–∫—É: –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∏–ª @@–ü–ï–†–í–´–ô@@, —Ç–æ —Å–ª–µ–¥—É—é—â–µ–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç @@–í–¢–û–†–û–ô@@ –∏ –Ω–∞–æ–±–æ—Ä–æ—Ç. –≠—Ç–∏ –º–µ—Ç–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n",
    "\n",
    "–¢–∞–∫–∂–µ —è –ø—Ä–æ–±–æ–≤–∞–ª –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥: —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–ª–∞, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, —è –ø—Ä–æ–±–æ–≤–∞–ª –¥–æ–±–∞–≤–ª—è—Ç—å –∫–∞–∂–¥–æ–µ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É, —Ç–æ –µ—Å—Ç—å \"@@–ü–ï–†–í–´–ô@@ <—Å–æ–æ–±—â–µ–Ω–∏–µ 1> @@–í–¢–û–†–û–ô@@ <—Å–æ–æ–±—â–µ–Ω–∏–µ 2>; @@–í–¢–û–†–û–ô@@ <—Å–æ–æ–±—â–µ–Ω–∏–µ 2> @@–ü–ï–†–í–´–ô@@ <—Å–æ–æ–±—â–µ–Ω–∏–µ 3>...\", –Ω–æ –ø—Ä–∏ —Ç–∞–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å–∏–ª—å–Ω–æ —É—Ö—É–¥—à–∏–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47ecf0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = \"@@–ü–ï–†–í–´–ô@@ \"\n",
    "second = \"@@–í–¢–û–†–û–ô@@ \"\n",
    "texts = [first + raw_texts[0]]\n",
    "last = 0\n",
    "for i in range(1, len(raw_texts)):\n",
    "    if users[i] == users[i-1]:\n",
    "        texts[-1] += \". \" + raw_texts[i]\n",
    "    else:\n",
    "        #texts[-1] += second + raw_texts[i]\n",
    "        #texts.append(first + raw_texts[i])\n",
    "        last = (last + 1) % 2\n",
    "        if not last:\n",
    "            texts.append(first + raw_texts[i])\n",
    "        else:\n",
    "            texts.append(second + raw_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b91ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "first = \"@@–ü–ï–†–í–´–ô@@ \"\n",
    "second = \" @@–í–¢–û–†–û–ô@@ \"\n",
    "texts = [first + raw_texts[0]]\n",
    "#last = 0\n",
    "for i in range(1, len(raw_texts)):\n",
    "    if users[i] == users[i-1]:\n",
    "        texts[-1] += \". \" + raw_texts[i]\n",
    "    else:\n",
    "        texts[-1] += second + raw_texts[i]\n",
    "        texts.append(first + raw_texts[i])\n",
    "        #last = (last + 1) % 2\n",
    "        #if not last:\n",
    "        #    texts.append(first + raw_texts[i])\n",
    "        #else:\n",
    "        #    texts.append(second + raw_texts[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bd27d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@@–ü–ï–†–í–´–ô@@ –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ –≤—Å–µ–º. –Ø —Ö–æ—Ç—å –∏ –ø–ª–æ—Ö–æ –∏–≥—Ä–∞—é –≤ —à–∞—Ö–º–∞—Ç—ã) –Ω–æ –æ—Ö–æ—Ç–æ –ø–æ–∏–≥—Ä–∞—Ç—å —Å –∫–µ–º –Ω–∏–±—É–¥—å –≤ –Ω–æ–≤–æ–º –≥–æ–¥—É',\n",
       " '@@–í–¢–û–†–û–ô@@ –í—Å–µ–º –ø—Ä–∏–≤–µ—Ç! –ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—Å—å üòÅ',\n",
       " '@@–ü–ï–†–í–´–ô@@ –ó–∞—Ä–∞–±–æ—Ç–∞–ª–æ))) —Ä–∞–¥ –≤—Å–µ—Ö –≤–∏–¥–µ—Ç—å))',\n",
       " '@@–í–¢–û–†–û–ô@@ –≠—Ö –∂–∞–ª–∫–æ –ø—Ä—è–º –ø–µ—Ä–µ–¥ –∫–∞–Ω–∏–∫—É–ª–∞–º–∏ –∫–ª—É–±–∞)',\n",
       " '@@–ü–ï–†–í–´–ô@@ –≠—Ç–æ –∑–∞–¥–µ–ª –Ω–∞ —Å–≤–µ—Ç–ª–æ–µ –±—É–¥—É—â–µ–µ)',\n",
       " '@@–í–¢–û–†–û–ô@@ –ß—Ç–æ–±—ã –Ω–∏–∫—Ç–æ –Ω–µ –æ—Å—Ç–∞–ª—Å—è –±–µ–∑ –ø–∞—Ä—Ç–Ω—ë—Ä–∞ –ø–æ –∏–≥—Ä–µ –≤ 2020! üòÅ',\n",
       " '@@–ü–ï–†–í–´–ô@@ –î–æ–±–∞–≤–ª—è–π—Ç–µ —Å–≤–æ–∏—Ö —à–∞—Ö–º–∞—Ç–Ω—ã—Ö –¥—Ä—É–∑–µ–π, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é —É –Ω–∞—Å –µ—Å—Ç—å –Ω–µ –≤—Å–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã...',\n",
       " '@@–í–¢–û–†–û–ô@@ –ü—Ä–∏–≤–µ—Ç! –ò —Å –ù–∞—Å—Ç—É–ø–∞—é—â–∏–º! \\n–ù–∞–¥–æ —Å–æ–±—Ä–∞—Ç—å—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ 20/20 –≤ –Ω–æ–≤–æ–º –≥–æ–¥—É!',\n",
       " '@@–ü–ï–†–í–´–ô@@ –û—á–µ–Ω—å –∫—Ä—É—Ç–æ , —á—Ç–æ –≥—Ä—É–ø–ø–∞ —Å–æ–∑–¥–∞–Ω–∞, –ø–∞—Ä—É —Ä–∞–∑ –ø—Ä–∏–µ–∑–∂–∞–ª –≤ WCC –∏ –ø—É—Å—Ç–æ) —Ç–µ–ø–µ—Ä—å –¥—É–º–∞—é –≤—Å–µ –±—É–¥–µ—Ç –æ–∫!)))',\n",
       " '@@–í–¢–û–†–û–ô@@ –° –ù–∞—Å—Ç—É–ø–∞—é—â–∏–º –ù–ì! –æ—Ñ–∏–≥–µ–Ω–Ω—ã–π –±–∞—Ä!']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef688194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db46a34",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6945df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50257, 10288,  1514,  ...,     0,     0,     0],\n",
       "        [50258,  7914,  6129,  ...,     0,     0,     0],\n",
       "        [50257,   999,  2050,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [50258,  9543,    16,  ...,     0,     0,     0],\n",
       "        [50257,  5452,  2696,  ...,     0,     0,     0],\n",
       "        [50258,   981,    16,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=256)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f0898",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –µ–≥–æ –Ω–∞ –æ–±—É—á–∞—é—â–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –≤ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "691f9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.data[\"labels\"] = data[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: value[idx] for key, value in self.data.items()}\n",
    "\n",
    "threshold = int(0.8 * len(inputs.data[\"input_ids\"]))\n",
    "train_data = {\n",
    "    key: value[:threshold] for key, value in inputs.data.items()\n",
    "}\n",
    "val_data = {\n",
    "    key: value[threshold:] for key, value in inputs.data.items()\n",
    "}\n",
    "\n",
    "train_dataset = TextDataset(train_data)\n",
    "val_dataset = TextDataset(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff3717",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —è –≤—ã–±—Ä–∞–ª 256. –ü–æ—Å–º–æ—Ç—Ä–∏–º, –≤ —Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –Ω–µ—Ç –ø–∞–¥–¥–∏–Ω–≥–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–Ω–∏ –æ–±—Ä–µ–∑–∞–Ω—ã)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97e5d887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x in train_dataset:\n",
    "    if x[\"attention_mask\"][-1] == 1:\n",
    "        cnt += 1\n",
    "        #rint(x)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "caeb2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33612\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c101422",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ—á–µ–Ω—å –º–∞–ª–æ, –∏ –≤—Ä—è–¥ –ª–∏ –æ–±—Ä–µ–∑–∞–Ω–Ω–∞—è —á–∞—Å—Ç—å –Ω–µ—Å–µ—Ç –∫–∞–∫—É—é-—Ç–æ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –ø–æ—ç—Ç–æ–º—É —è —Å—á–∏—Ç–∞—é 256 –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152177c",
   "metadata": {},
   "source": [
    "–£ –º–æ–¥–µ–ª–µ–π HuggingFace –µ—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–µ–π –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–°–æ—Ö—Ä–∞–Ω–∏–º –∏—Å—Ö–æ–¥–Ω—É—é –º–æ–¥–µ–ª—å, –∑–∞–¥–∞–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å—Ç–∏–º –µ–≥–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9da80555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in original_model\\config.json\n",
      "Model weights saved in original_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"original_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "012681b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1, #–ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–ø–æ—Ö–∞—Ö –º–æ–¥–µ–ª—å –∑–∞–º–µ—Ç–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è\n",
    "    save_steps=5000,\n",
    "    output_dir='./model_output',\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    disable_tqdm = False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4c2a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1db901",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ –Ω–∞—á–∞–ª–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dabbf784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8404\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2102' max='1051' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1051/1051 1:51:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 27.32219886779785,\n",
       " 'eval_runtime': 828.4204,\n",
       " 'eval_samples_per_second': 10.145,\n",
       " 'eval_steps_per_second': 1.269}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e8c6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 33612\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16806\n",
      "  Number of trainable parameters = 355875840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16806' max='16806' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16806/16806 5:39:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.356852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.350833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.275700</td>\n",
       "      <td>0.345955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8404\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./model_output\\checkpoint-5000\n",
      "Configuration saved in ./model_output\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./model_output\\checkpoint-5000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8404\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./model_output\\checkpoint-10000\n",
      "Configuration saved in ./model_output\\checkpoint-10000\\config.json\n",
      "Model weights saved in ./model_output\\checkpoint-10000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8404\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./model_output\\checkpoint-15000\n",
      "Configuration saved in ./model_output\\checkpoint-15000\\config.json\n",
      "Model weights saved in ./model_output\\checkpoint-15000\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16806, training_loss=0.2978854185624391, metrics={'train_runtime': 20351.398, 'train_samples_per_second': 1.652, 'train_steps_per_second': 0.826, 'total_flos': 1.5607743872237568e+16, 'train_loss': 0.2978854185624391, 'epoch': 1.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684acce0",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–∏–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7dd5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in fine-tuned ccm2\\config.json\n",
      "Model weights saved in fine-tuned ccm2\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"fine-tuned ccm2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a45de",
   "metadata": {},
   "source": [
    "–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –±—ã–ª–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞ –º–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è, —Å–∏–º–≤–æ–ª—ã –ø–∞–¥–¥–∏–Ω–≥–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–ø–∞–¥–∞—é—Ç –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é. –û—á–∏—Å—Ç–∏–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç –Ω–∏—Ö, –∞ —Ç–∞–∫–∂–µ –æ—Ç –º–µ—Ç–æ–∫ @@–ü–ï–†–í–´–ô@@ –∏ @@–í–¢–û–†–û–ô@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2581f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_response(text, start_marker=\"@@–í–¢–û–†–û–ô@@\", end_marker=\"@@–ü–ï–†–í–´–ô@@\"):\n",
    "    text = re.sub(r'<pad>', '', text)\n",
    "    \n",
    "    match = re.search(f\"{re.escape(start_marker)}(.+?){re.escape(end_marker)}\", text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    \n",
    "    match = re.search(f\"{re.escape(start_marker)}(.+)\", text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    \n",
    "    return \"–û–®–ò–ë–ö–ê\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8effde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50261 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ü§£üôåüèª\\u200d‚ôÄÔ∏è',\n",
       " 'ü§£üëåüèªüôèüí´. —è –±—ã —Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º –ø–æ–∏–≥—Ä–∞–ª, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –∫–æ–º–ø–∞, –ø–æ—ç—Ç–æ–º—É –∏ –Ω–µ –∑–Ω–∞—é, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å)',\n",
       " 'ü§£üôà. –∞ –∫–∞–∫–æ–π —É —Ç–µ–±—è —Ä–µ–π—Ç–∏–Ω–≥?']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "inputs = tokenizer('@@–ü–ï–†–í–´–ô@@ –ø—Ä–∏–≤–µ—Ç, —Ç—ã –∏–≥—Ä–∞–µ—à—å –≤ —à–∞—Ö–º–∞—Ç—ã? @@–í–¢–û–†–û–ô@@ ', return_tensors='pt')\n",
    "generated_token_ids = model.generate(\n",
    "    **inputs,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=1.3,\n",
    "    repetition_penalty=1.2,\n",
    "    length_penalty=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=40\n",
    ")\n",
    "context_with_response = [tokenizer.decode(sample_token_ids) for sample_token_ids in generated_token_ids]\n",
    "context_with_response_cleaned = [extract_response(text) for text in context_with_response]\n",
    "context_with_response_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbe4eb",
   "metadata": {},
   "source": [
    "–ù–æ—Ä–º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46205c3",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –æ–±–µ—Ä–Ω–µ–º —ç—Ç–æ –≤ –±–æ—Ç–∞: https://t.me/chess_club_moscow_gpt_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de85748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
